<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Practical AI use cases for nonprofits | Bridges Strategy</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="styles.css">
</head>
<body>

<header>
  <img 
    src="assets/logo.png" 
    alt="Bridges Strategy logo"
    class="logo"
  />
  <h1>Bridges Strategy</h1>
  <p class="subtitle">
    Practical AI strategy for nonprofits with limited resources.
  </p>
</header>

<main>

<section>
  <h2>Practical AI use cases for nonprofits</h2>
  <p>
    Nonprofit organizations are often asked how they plan to use artificial
    intelligence, even when they operate with limited resources, high trust
    obligations, and little tolerance for error.
  </p>
  <p>
    This page outlines examples of how AI is beginning to show up in nonprofit
    work, along with the conditions that tend to make these uses helpful or
    risky. The goal is not to encourage adoption, but to support clearer
    thinking about where AI may reduce burden, where it may add risk, and where
    restraint is often the better choice.
  </p>
  <p>
    These examples are illustrative, not prescriptive.
  </p>
</section>

<section>
  <h2>How to read this page</h2>
  <p>Each use case is described along three dimensions:</p>
  <ul>
    <li><strong>Readiness</strong> — what skills, data, and governance need to exist first</li>
    <li><strong>Risk</strong> — who is affected if something goes wrong</li>
    <li><strong>Reversibility</strong> — how easy it is to correct mistakes or withdraw use</li>
  </ul>
  <p>
    In practice, many challenges arise not from the technology itself, but from
    overestimating readiness, underestimating risk, or treating AI outputs as
    authoritative when they are not.
  </p>
</section>

<section>
  <h2>Low-risk, internal use cases</h2>
  <p>
    Where most organizations should start, if anywhere.
  </p>

  <h3>Internal document drafting and revision</h3>
  <p><strong>What it helps with</strong><br>
    Producing first drafts of internal documents such as memos, policies,
    agendas, or briefing notes.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Outputs can be generic or misaligned with organizational tone.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Clear ownership of final content and human accountability.
  </p>

  <h3>Summarizing long reports and research</h3>
  <p><strong>What it helps with</strong><br>
    Reducing the effort required to digest long reports or research.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Nuance can be lost and assumptions introduced.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Critical review and contextual understanding.
  </p>

  <h3>Grant application first drafts and reframing</h3>
  <p><strong>What it helps with</strong><br>
    Generating early drafts or alternative framings.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Language can become formulaic or disconnected from real work.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Strong internal clarity about mission and programs.
  </p>

  <h3>Internal knowledge access</h3>
  <p><strong>What it helps with</strong><br>
    Making policies and guidance easier to navigate.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Confidently surfaces outdated or inconsistent information.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Up-to-date documentation and clear boundaries.
  </p>

  <h3>Meeting preparation and recap support</h3>
  <p><strong>What it helps with</strong><br>
    Preparing agendas or summarizing notes.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Misses nuance and informal dynamics.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Human review and contextual adjustment.
  </p>

  <h3>Brainstorming and outlining</h3>
  <p><strong>What it helps with</strong><br>
    Generating options and outlines.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Ideas may be superficial or unrealistic.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Use as a catalyst, not direction.
  </p>
</section>

<section>
  <h2>Medium-risk, operational support</h2>
  <p>
    Potentially useful, but only with clear guardrails and human oversight.
  </p>

  <h3>Fundraising research and prospect synthesis</h3>
  <p><strong>What it helps with</strong><br>
    Summarizing publicly available information.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Shallow or misleading insights.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Clear expectations and human validation.
  </p>

  <h3>Program evaluation and outcome synthesis</h3>
  <p><strong>What it helps with</strong><br>
    Surfacing themes from evaluation data.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Flattens nuance and context.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Strong evaluation practices and transparency.
  </p>

  <h3>Communications support with review</h3>
  <p><strong>What it helps with</strong><br>
    Drafting and revising communications.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Generic tone or loss of voice.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Brand guidance and mandatory review.
  </p>

  <h3>Scenario exploration for planning</h3>
  <p><strong>What it helps with</strong><br>
    Exploring strategic options.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Poor grounding in real constraints.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Experienced facilitation and clear assumptions.
  </p>

  <h3>Policy and briefing note preparation</h3>
  <p><strong>What it helps with</strong><br>
    Early drafts for leadership.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Obscures uncertainty or context.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Editorial oversight and accountability.
  </p>
</section>

<section>
  <h2>High-risk or cautionary areas</h2>
  <p>
    Often discussed, rarely appropriate early.
  </p>

  <h3>Constituent-facing chatbots</h3>
  <p><strong>What it helps with</strong><br>
    Automated responses to common questions.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Incorrect or inappropriate information.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Clear boundaries, escalation, and accountability.
  </p>

  <h3>Automated eligibility or decision-making</h3>
  <p><strong>What it helps with</strong><br>
    Supporting triage or prioritization.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Encodes bias and obscures judgment.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Governance, transparency, and community input.
  </p>

  <h3>Voice agents or multilingual intake</h3>
  <p><strong>What it helps with</strong><br>
    Lowering access barriers.
  </p>
  <p><strong>Why it often disappoints</strong><br>
    Misinterpretation and exclusion.
  </p>
  <p><strong>What needs to be true first</strong><br>
    Consent, fallback to humans, and monitoring.
  </p>
</section>

<section>
  <h2>How to use this page</h2>
  <p>
    These examples are intended as conversation starters. They can help
    leadership teams and boards reflect on readiness, risk, and responsibility
    before deciding whether to move forward.
  </p>
  <p>
    If it is helpful, I have also built a short AI readiness conversation that
    reflects how I approach these discussions in practice.
  </p>
  <p>
    <a href="https://chatgpt.com/g/g-691605f19d248191a5eacf41f9de7339-ai-readiness-coach-for-nonprofits">View the AI Readiness Conversation</a>
  </p>
</section>

</main>

<footer>
  <p>© Bridges Strategy · AI strategy for mission-driven organizations</p>
</footer>

</body>
</html>
